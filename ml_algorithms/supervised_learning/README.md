# Supervised Learning

Supervised learning algorithms learn from labeled training data to make predictions on new, unseen data. These algorithms are used when we have input-output pairs and want to learn the mapping between them.

## Categories

### Regression
Algorithms for predicting continuous numerical values.

- [Linear Regression](regression/linear_regression.py) - Finds linear relationships between features and target
- [Polynomial Regression](regression/polynomial_regression.py) - Models non-linear relationships
- [Ridge/Lasso/ElasticNet](regression/ridge_lasso_elasticnet.py) - Regularized linear regression
- [Decision Tree Regressor](regression/decision_tree_regressor.py) - Tree-based regression
- [Random Forest Regressor](regression/random_forest_regressor.py) - Ensemble of decision trees
- [Gradient Boosting Regressor](regression/gradient_boosting_regressor.py) - Sequential tree building
- [SVR](regression/svr.py) - Support Vector Regression
- [KNN Regressor](regression/knn_regressor.py) - K-Nearest Neighbors for regression

### Classification
Algorithms for predicting categorical class labels.

- [Logistic Regression](classification/logistic_regression.py) - Probability-based classification
- [K-Nearest Neighbors](classification/k_nearest_neighbors.py) - Distance-based classification
- [Support Vector Machine](classification/support_vector_machine.py) - Maximum margin classification
- [Naive Bayes](classification/naive_bayes.py) - Probabilistic classification
- [Decision Tree Classifier](classification/decision_tree_classifier.py) - Tree-based classification
- [Random Forest Classifier](classification/random_forest_classifier.py) - Ensemble classification
- [Gradient Boosting Classifier](classification/gradient_boosting_classifier.py) - Sequential classification
- [Perceptron](classification/perceptron.py) - Single-layer neural network
- [Neural Network MLP](classification/neural_network_mlp.py) - Multi-layer perceptron
